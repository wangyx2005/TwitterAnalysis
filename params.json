{
  "name": "TwitterAnalysis",
  "tagline": "Really time Twitter analysis on what is public attitude on hot button.",
  "body": "### Project Introduction\r\nSocial media like `facebook` and `twitter` have become an important way to distribute news. Also people nowadays tend to post their feeling in social networks. Consequently, data collected from social networks implies the most up-to-date topics and public feelings about what is on their mind. In this project, we try to approach popular topics or a specific topic analytics with real-time tweets.\r\n\r\n### Motivation\r\nTwitter provides public API for developers to obtain data. With its `stream API`, we can access real-time data from twitter to achieve live data analysis. With this idea, we find a proper framework used to complete streaming analytic--__Spark__. \r\n\r\n  Around __6000 tweets__ are sent every second. To process these streaming data, the framework we choose should be able to deal with very large data set. Spark is scalable to large clusters. So it can deal with huge dataset both in computing and storage. Second-scale latencies are needed in live analytics. In this aspect, spark is famous for its process speed. Instead of disk-accessing, the computation spark adapted is memory-data accessing. For those MapReduce that can be fit in memory, spark is almost 100 times faster than Hadoop. For disk MapReduce, Spark is still 10 times faster. As a scalable programming framework which is able to deal with huge dataset, Spark has excellent strategy to ensure fault tolerance in an efficient way. When it comes to data storage, unlike Hadoop MapReduce that replicate data to achieve fault-tolerance, Spark records data generation to recreate error data. If no data fault happens, the cost is zero. Moreover, with Spark, not only __streaming data analytics__ can be achieved, __batch data analysis__ is also integrated.\r\n\r\n### About Spark\r\nThe following picture shows the eco-system of Spark. At the bottom is Spark Core which is the general execution engine for the whole platform. It provides Java, Scala, and Python APIs for ease of development.\r\n\r\n![Spark](https://github.com/wangyx2005/TwitterAnalysis/blob/master/proposal/spark_intro.png?raw=true)\r\n\r\nAbove this core, Spark also provides four libraries to support a variety of applications. Spark DataFrames makes SQL-like query available in distributed file system. Spark Streaming library enables powerful interactive and analytical applications across both streaming and historical data, while inheriting Spark’s ease of use and fault tolerance characteristics. It readily integrates with a wide variety of popular data sources, including Twitter. MLlib and GraphX provide machine leaning and graph computation library respectively, which facilitate abundant well-performed popular Algorithms. With various APIs and readily to use libraries, fancy twitter analytics development is potentially to achieve.\r\n\r\nFor more detailed information about Spark, please visit <http://spark.apache.org/>\r\n\r\n### Approach\r\nAs mentioned above, the data we use in this project is real-time stream data from twitter. In fetched twits, we can get more than text postings. Twitter APIs provide almost every feature appeared on its website, for instance, hash tagged topics and geo locations. Taking advantage of these features, we can explore how much a subject been discussed, people’s feeling about a certain subject and more interestingly, how these subjects were distributed. The following picture shows the general workflow.\r\n\r\n![workflow](https://github.com/wangyx2005/TwitterAnalysis/blob/master/proposal/workflow.png?raw=true)\r\n\r\n##### Step 1\r\nGet familiar with twitter API and spark stream—real-time word count. \r\n\r\nIn this stage, the biggest challenge are to set up spark platform and to know how to use twitter API. With these resources, we can easily implement a real-time word count application.\r\n\r\n##### Step 2\r\nAs above application been implemented, we should find a method to show the outcome of word-counting (which is the topic selection). We can store these result in a database and display them later. But it is by no means the best way. Showing the real-time data analysis with a live illustration is the ideal. So this could be the challenge of this step. \r\n\r\n##### Step 3\r\nSentiment analysis can be done under the support of spark machine learning. And also, we find a training dataset from Kaggle that can be used to contribute our own sentiment analysis model.  However, since none of us has the experience with spark MLlib, this approach could be a serious issue.  \r\n\r\nFortunately, we have a backup approach. Under the direction of Dr. Sharma, we find IBM Bluemix works really well with sentiment analytics. Since it is readily get access with twitter stream API, Bluemix can be used in a very convenient way—we just need to drag the components we need and connect them. We also noticed that it can connect with Spark directly, but for this part, we need to explore further. \r\n\r\n##### Step 4\r\nGeo location of tweets is provided by API. If we can take advantage of this information, we can analyze topics’ region feature. The problem here is that geo location provided by twitter API is just coordinates. It could be difficult to implement it with a specific city or even state. But even though location analysis cannot be achieved in an accurate way, we can still do some rough analytics. \r\n\r\n### Time line\r\n* Step 1      present - Apr.10\r\n* Step 2      Apr.11 - Apr.20\r\n* Step 3&4    Apr.21 - End of semester\r\n\r\n### Deliverable\r\nThe ideally deliverable would be a website hosting this real-time twitter analysis. However, because none of us has experience setting up website, we may submit a final report in stand. \r\n\r\n### Weekly updates\r\n##### Week 0\r\n* generated proposal, presentation, make the project page on GitHub\r\n* Played with IBM Bluemix a little bit. Bluemix is indeed a powerful tool. And if we do not need to perform the analysis on-fly, we should just use Bluemix. However, because the free trial account on Bluemix has strict limitation on the usage of Apache Spark and the trial account can only access 1 month, we decided we will not use Bluemix as the main part of our project. However, we would consider it as a backup for our project.\r\n\r\n### Authors and Contributors\r\nYuxing Wang @wangyx2005, Jing Cui @Jingcui01 Zhenying Tao @Shally1130\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}